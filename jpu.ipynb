{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/srihari/tf2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/srihari/tf2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/srihari/tf2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/srihari/tf2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/srihari/tf2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/srihari/tf2/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow 2.0.0-beta1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/srihari/tf2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/srihari/tf2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/srihari/tf2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/srihari/tf2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/srihari/tf2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/srihari/tf2/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from resnet import ResNet101\n",
    "print('TensorFlow', tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(tensor, num_filters, kernel_size, padding='same', strides=1, dilation_rate=1, w_init='he_normal'):\n",
    "    x = tf.keras.layers.Conv2D(filters=num_filters, \n",
    "                               kernel_size=kernel_size, \n",
    "                               padding=padding, \n",
    "                               strides=strides, \n",
    "                               dilation_rate=dilation_rate, \n",
    "                               kernel_initializer=w_init, \n",
    "                               use_bias=False)(tensor)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "def sepconv_block(tensor, num_filters, kernel_size, padding='same', strides=1, dilation_rate=1, w_init='he_normal'):\n",
    "    x = tf.keras.layers.SeparableConv2D(filters=num_filters, \n",
    "                                        depth_multiplier=1, \n",
    "                                        kernel_size=kernel_size, \n",
    "                                        padding=padding, \n",
    "                                        strides=strides, \n",
    "                                        dilation_rate=dilation_rate, \n",
    "                                        depthwise_initializer=w_init, \n",
    "                                        use_bias=False)(tensor)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.ReLU()(x)\n",
    "    return x\n",
    "\n",
    "def JPU(endpoints:list, out_channels=512):\n",
    "    h, w = endpoints[1].shape.as_list()[1:3]\n",
    "    for i in range(1, 4):\n",
    "        endpoints[i] = conv_block(endpoints[i], out_channels, 3)\n",
    "        if i != 1:\n",
    "            h_t, w_t = endpoints[i].shape.as_list()[1:3]\n",
    "            scale = (h // h_t, w // w_t)\n",
    "            endpoints[i] = tf.keras.layers.UpSampling2D(size=scale, interpolation='bilinear')(endpoints[i])\n",
    "    yc = tf.keras.layers.Concatenate(axis=-1)(endpoints[1:])\n",
    "    ym = []\n",
    "    for rate in [1, 2 , 4, 8]:\n",
    "        ym.append(sepconv_block(yc, 512, 3, dilation_rate=rate))\n",
    "    y = tf.keras.layers.Concatenate(axis=-1)(ym)\n",
    "    return endpoints, y\n",
    "\n",
    "def ASPP(tensor):\n",
    "    dims = tensor.shape.as_list()\n",
    "\n",
    "    y_pool = tf.keras.layers.AveragePooling2D(pool_size=(\n",
    "        dims[1], dims[2]), name='average_pooling')(tensor)\n",
    "    y_pool = conv_block(y_pool, num_filters=256, kernel_size=1)\n",
    "    \n",
    "    h_t, w_t = y_pool.shape.as_list()[1:3]\n",
    "    scale = dims[1]//h_t, dims[2]//w_t\n",
    "    y_pool = tf.keras.layers.UpSampling2D(size=scale, interpolation='bilinear')(y_pool)\n",
    "    \n",
    "    y_1 = conv_block(tensor, num_filters=256, kernel_size=1, dilation_rate=1)\n",
    "    y_6 = conv_block(tensor, num_filters=256, kernel_size=3, dilation_rate=6)\n",
    "    y_6.set_shape([None, dims[1], dims[2], 256])\n",
    "    y_12 = conv_block(tensor, num_filters=256, kernel_size=3, dilation_rate=12)\n",
    "    y_12.set_shape([None, dims[1], dims[2], 256])\n",
    "    y_18 = conv_block(tensor, num_filters=256, kernel_size=3, dilation_rate=18)\n",
    "    y_18.set_shape([None, dims[1], dims[2], 256])\n",
    "    \n",
    "    y = tf.keras.layers.Concatenate(axis=-1)([y_pool, y_1, y_6, y_12, y_18])\n",
    "    y = conv_block(y, num_filters=256, kernel_size=1)\n",
    "    return y\n",
    "\n",
    "def JPU_DeepLab(img_height=1024, img_width=1024, nclasses=19):\n",
    "    base_model = ResNet101(include_top=False, \n",
    "                           input_shape=[img_height, img_width, 3], \n",
    "                           weights=None)\n",
    "    endpoint_names = ['conv2_block3_out', 'conv3_block4_out', 'conv4_block23_out', 'conv5_block3_out']\n",
    "    endpoints = [base_model.get_layer(x).output for x in endpoint_names]\n",
    "\n",
    "    _, image_features = JPU(endpoints)\n",
    "\n",
    "    x_a = ASPP(image_features)\n",
    "    h_t, w_t = x_a.shape.as_list()[1:3]\n",
    "    scale = (img_height/4) // h_t, (img_width/4) // w_t\n",
    "    x_a = tf.keras.layers.UpSampling2D(size=scale, interpolation='bilinear')(x_a)\n",
    "\n",
    "    x_b = base_model.get_layer('conv2_block3_out').output\n",
    "    x_b = conv_block(x_b, num_filters=48, kernel_size=1)\n",
    "    \n",
    "    x = tf.keras.layers.Concatenate(axis=-1)([x_a, x_b])\n",
    "    x = conv_block(x, num_filters=256, kernel_size=3)\n",
    "    x = conv_block(x, num_filters=256, kernel_size=3)\n",
    "    h_t, w_t = x.shape.as_list()[1:3]\n",
    "    scale = img_height // h_t, img_width // w_t\n",
    "    x = tf.keras.layers.UpSampling2D(size=scale, interpolation='bilinear')(x)\n",
    "\n",
    "    x = tf.keras.layers.Conv2D(nclasses, (1, 1), name='output_layer')(x)\n",
    "    model = tf.keras.Model(inputs=base_model.input, outputs=x, name='JPU')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = JPU_DeepLab(480, 480, 34)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
